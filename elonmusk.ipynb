{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycontractions  import Contractions\n",
    "import string\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from flair.models import SequenceTagger, MultiTagger\n",
    "from flair.data import Sentence\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english')\n",
    "# print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = get_stop_words('en')\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Tweets Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2668 entries, 0 to 2667\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Tweets          2668 non-null   object        \n",
      " 1   Retweets        2668 non-null   int64         \n",
      " 2   Likes           2668 non-null   int64         \n",
      " 3   Date            2668 non-null   datetime64[ns]\n",
      " 4   Cleaned_Tweets  2668 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 104.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/cleandata.csv', parse_dates=['Date'],encoding = \"utf-8\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_info(dataframe):\n",
    "    cols_list = dataframe.columns.tolist()\n",
    "    data_types = df.dtypes    \n",
    "    \n",
    "    for col in cols_list:        \n",
    "        # get the number of unique entries for each column\n",
    "        no_unique_value = dataframe[col].nunique()\n",
    "        print(f'The number of unique values for column {col} is {no_unique_value}')\n",
    "\n",
    "        # Check for the data type and get the min and max value\n",
    "        if data_types[col] != 'object':\n",
    "            min_value = dataframe[col].min()\n",
    "            max_value = dataframe[col].max()\n",
    "            print(f'The min value for column {col} is {min_value}')\n",
    "            print(f'The max value for column {col} is {max_value}\\n')\n",
    "        else:\n",
    "            print('\\n')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values for column Tweets is 2642\n",
      "\n",
      "\n",
      "The number of unique values for column Retweets is 1834\n",
      "The min value for column Retweets is 41\n",
      "The max value for column Retweets is 681707\n",
      "\n",
      "The number of unique values for column Likes is 2598\n",
      "The min value for column Likes is 933\n",
      "The max value for column Likes is 4780787\n",
      "\n",
      "The number of unique values for column Date is 2668\n",
      "The min value for column Date is 2022-01-27 21:00:09\n",
      "The max value for column Date is 2022-10-27 16:17:39\n",
      "\n",
      "The number of unique values for column Cleaned_Tweets is 2382\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_basic_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = Contractions('GoogleNews-vectors-negative300.bin')\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           thanks\n",
       "1                                       Absolutely\n",
       "2                         Dear Twitter Advertisers\n",
       "3    Meeting a lot of cool people at Twitter today\n",
       "4           Entering Twitter HQ – let that sink in\n",
       "Name: Cleaned_Tweets, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = text.strip()\n",
    "    # Fix quotes\n",
    "    text = text.replace(\"’\", \"'\") \\\n",
    "        .replace(\"‘\", \"'\") \\\n",
    "        .replace(\"”\", '\"') \\\n",
    "        .replace(\"“\", '\"')\n",
    "\n",
    "    # Replace &amp; with and\n",
    "    text = text.replace('&amp;', 'and')\n",
    "\n",
    "    # Fix sentences which does not have space after full stop\n",
    "    text = text.replace('.', '. ')\n",
    "    \n",
    "    # Fix contractions\n",
    "    text = list(cont.expand_texts([text], precise=True))[0]\n",
    "\n",
    "    # Remove punctuations\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df['Cleaned_Tweets'] = df['Cleaned_Tweets'].apply(clean)\n",
    "df['Cleaned_Tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Token_Counts'] = df['Cleaned_Tweets'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets with less than 3 tokens\n",
    "df = df[df['Token_Counts'] > 2].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2094, 6)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Emanuel/bertweet-emotion-base\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Emanuel/bertweet-emotion-base\"\n",
    ")\n",
    "device = -1 #torch.cuda.current_device() if torch.cuda.is_available else -1\n",
    "model_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'label': 'anger', 'score': 0.704805850982666...\n",
       "1    [{'label': 'joy', 'score': 0.9869217872619629}...\n",
       "2    [{'label': 'joy', 'score': 0.8734441995620728}...\n",
       "3    [{'label': 'sadness', 'score': 0.3829310834407...\n",
       "4    [{'label': 'anger', 'score': 0.415039986371994...\n",
       "Name: Emotion_Scores, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion_Scores'] = model_pipeline(df['Cleaned_Tweets'].to_list(), top_k=None)\n",
    "df['Emotion_Scores'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion1</th>\n",
       "      <th>Emotion2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion1 Emotion2\n",
       "0    anger      joy\n",
       "1      joy     love\n",
       "2      joy    anger\n",
       "3  sadness    anger\n",
       "4    anger  sadness"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign top 2 emotions\n",
    "df['Emotion1'] = df['Emotion_Scores'].apply(lambda x: x[0]['label'])\n",
    "df['Emotion1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "vectorizer = KeyphraseCountVectorizer(pos_pattern='<NNP.*>+')\n",
    "df['Noun_Keyphrases_Score'] = kw_model.extract_keywords(docs=df['Cleaned_Tweets'].to_list(), vectorizer=vectorizer, stop_words='english', top_n=5)\n",
    "df['Noun_Keyphrases'] = df['Noun_Keyphrases_Score'].apply(lambda record: [x[0] for x in record])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twitter', 0.6289)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Noun_Keyphrases_Score'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [twitter]\n",
       "1                    [twitter, lot]\n",
       "2       [twitter hq, twitter, sink]\n",
       "3                         [twitter]\n",
       "4                                []\n",
       "                   ...             \n",
       "2089                    [manganese]\n",
       "2090              [manganese, iron]\n",
       "2091                             []\n",
       "2092                       [office]\n",
       "2093                             []\n",
       "Name: Noun_Keyphrases, Length: 2094, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Noun_Keyphrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting score types for serialization\n",
    "def fix_float_type(input):\n",
    "    return [(x[0], str(x[1])) for x in input]\n",
    "df['Noun_Keyphrases_Score'] = df['Noun_Keyphrases_Score'].apply(fix_float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'twitter': 86,\n",
       "         'lot': 33,\n",
       "         'twitter hq': 1,\n",
       "         'sink': 5,\n",
       "         'wish': 6,\n",
       "         'new york times': 1,\n",
       "         'vitalik': 1,\n",
       "         'booster': 16,\n",
       "         'silicon valley': 1,\n",
       "         'polytopia': 3,\n",
       "         'war': 22,\n",
       "         'life': 28,\n",
       "         'kasparov': 1,\n",
       "         'chess': 4,\n",
       "         'iphone': 2,\n",
       "         'blue': 2,\n",
       "         'time': 59,\n",
       "         'starlink': 72,\n",
       "         'dod': 4,\n",
       "         'spacex': 48,\n",
       "         'thingreal': 1,\n",
       "         'wapo': 4,\n",
       "         'neuralink': 4,\n",
       "         'nov': 1,\n",
       "         'long': 25,\n",
       "         'change': 9,\n",
       "         'belgium': 1,\n",
       "         'switzerland': 1,\n",
       "         'beta': 26,\n",
       "         'next': 41,\n",
       "         'randd': 2,\n",
       "         'tbh': 8,\n",
       "         'gps': 4,\n",
       "         'headline': 1,\n",
       "         'signal': 12,\n",
       "         'un ass': 1,\n",
       "         'un': 5,\n",
       "         'giga berlin': 4,\n",
       "         'giga': 13,\n",
       "         'tesla': 138,\n",
       "         'kremlin': 1,\n",
       "         'putin': 2,\n",
       "         'peace': 7,\n",
       "         'nice': 11,\n",
       "         'ukraine': 27,\n",
       "         'russia': 23,\n",
       "         'crimea': 10,\n",
       "         'cuba': 1,\n",
       "         'bakhmut': 1,\n",
       "         'btw': 6,\n",
       "         'humor': 6,\n",
       "         'compromise': 1,\n",
       "         'destruction': 4,\n",
       "         'falcon': 20,\n",
       "         'team': 39,\n",
       "         'earth': 33,\n",
       "         'energy': 21,\n",
       "         'vox populi vox dei': 1,\n",
       "         'haha': 34,\n",
       "         'internet': 17,\n",
       "         'burnt hair': 7,\n",
       "         'smart': 8,\n",
       "         'drone war': 1,\n",
       "         'smart summon': 1,\n",
       "         'summon': 2,\n",
       "         'optimus': 6,\n",
       "         'america crimea': 1,\n",
       "         'afghanistan': 1,\n",
       "         'america': 10,\n",
       "         'ww3': 3,\n",
       "         'nato': 1,\n",
       "         'civilization': 19,\n",
       "         'use': 22,\n",
       "         'pearl harbor': 1,\n",
       "         'importance': 3,\n",
       "         'usa': 4,\n",
       "         'us': 26,\n",
       "         'latter': 6,\n",
       "         'starlinks': 9,\n",
       "         'starship': 27,\n",
       "         'rud': 3,\n",
       "         'ramen gtgt lambos': 1,\n",
       "         'fancy': 1,\n",
       "         'lonely': 1,\n",
       "         'kbg': 1,\n",
       "         'venn': 1,\n",
       "         'boss baby das baby': 1,\n",
       "         'das baby': 2,\n",
       "         'boss baby': 2,\n",
       "         'hijinks': 2,\n",
       "         'das boot': 1,\n",
       "         'fate': 5,\n",
       "         'irony': 6,\n",
       "         'super': 22,\n",
       "         'appreciated': 2,\n",
       "         'ironically gps': 1,\n",
       "         'humanity': 17,\n",
       "         'zero': 10,\n",
       "         'europe': 3,\n",
       "         'mad': 2,\n",
       "         'may': 18,\n",
       "         'mars': 18,\n",
       "         'burn': 4,\n",
       "         'leo': 2,\n",
       "         'goal': 10,\n",
       "         'iran': 1,\n",
       "         'lockheed': 1,\n",
       "         'boeing': 1,\n",
       "         'corruption': 3,\n",
       "         'envy': 2,\n",
       "         'madness': 2,\n",
       "         'power': 19,\n",
       "         'watt': 1,\n",
       "         'viasat': 2,\n",
       "         'day': 28,\n",
       "         'elon': 2,\n",
       "         'glad': 4,\n",
       "         'doge': 6,\n",
       "         'bremmer': 1,\n",
       "         'sam': 1,\n",
       "         'shield': 2,\n",
       "         'tower': 4,\n",
       "         'palo alto': 2,\n",
       "         'autopilot': 2,\n",
       "         'office': 4,\n",
       "         'story': 14,\n",
       "         'night': 12,\n",
       "         'friend': 7,\n",
       "         'dojo': 2,\n",
       "         'bf16': 1,\n",
       "         'dragons': 2,\n",
       "         'fedorov': 1,\n",
       "         'ft': 1,\n",
       "         'wheel': 3,\n",
       "         'tesla ai day': 6,\n",
       "         'tesla ai': 8,\n",
       "         'ai day': 9,\n",
       "         'ai': 25,\n",
       "         'spacex dragon': 1,\n",
       "         'dragon': 6,\n",
       "         'mf': 1,\n",
       "         'tesla semi': 1,\n",
       "         'dec': 3,\n",
       "         'semi': 2,\n",
       "         'zaporizhzhia': 1,\n",
       "         'water': 5,\n",
       "         'prorussia': 2,\n",
       "         'ford': 2,\n",
       "         'gm': 4,\n",
       "         'hard': 22,\n",
       "         'bs': 3,\n",
       "         'spacexs': 3,\n",
       "         'kosovo': 1,\n",
       "         'donbas': 1,\n",
       "         'bot': 9,\n",
       "         'ukrainerussia peace redo': 1,\n",
       "         'khrushchevs': 1,\n",
       "         'wellsaid': 1,\n",
       "         'darkness': 3,\n",
       "         'light': 4,\n",
       "         'tesla sim': 1,\n",
       "         'tbc': 1,\n",
       "         'prufrock ii': 1,\n",
       "         'russians': 2,\n",
       "         'trois': 1,\n",
       "         'greatest': 3,\n",
       "         'california': 8,\n",
       "         'south padre island': 1,\n",
       "         'south padre': 2,\n",
       "         'starbase': 7,\n",
       "         'cybertruck': 2,\n",
       "         'submarines': 1,\n",
       "         'airobotics': 1,\n",
       "         'demos': 1,\n",
       "         'kph': 1,\n",
       "         'maritime': 1,\n",
       "         'tesla megapack': 1,\n",
       "         'hawaii': 1,\n",
       "         'henrik fisker': 1,\n",
       "         'karma': 1,\n",
       "         'nn': 3,\n",
       "         'singed': 1,\n",
       "         'saxon': 3,\n",
       "         'lenin': 2,\n",
       "         'ludendorffs': 1,\n",
       "         'siegel': 1,\n",
       "         'amazon': 2,\n",
       "         'popmech': 1,\n",
       "         'update': 8,\n",
       "         'replacement': 2,\n",
       "         'weems st': 1,\n",
       "         'austin': 7,\n",
       "         'giga texas': 4,\n",
       "         'texas': 7,\n",
       "         'openai': 2,\n",
       "         'dalle': 1,\n",
       "         'brooklyn': 1,\n",
       "         'boys high': 1,\n",
       "         'africa': 2,\n",
       "         'south africa': 1,\n",
       "         'mps': 1,\n",
       "         'cape': 3,\n",
       "         'q2': 2,\n",
       "         'brownsville': 2,\n",
       "         'port': 1,\n",
       "         'november': 4,\n",
       "         'unsurprisingly reich': 1,\n",
       "         'curiouser': 1,\n",
       "         'bro': 4,\n",
       "         'fsd beta': 9,\n",
       "         'fsd': 22,\n",
       "         'safety': 11,\n",
       "         'autopilotai': 3,\n",
       "         'zambia': 1,\n",
       "         'canada': 7,\n",
       "         'high bay': 4,\n",
       "         'fed': 3,\n",
       "         'problematic': 1,\n",
       "         'antarctica': 2,\n",
       "         'next gen starlink': 1,\n",
       "         'kg': 1,\n",
       "         'alexander': 1,\n",
       "         'hyperloop': 4,\n",
       "         'stars': 5,\n",
       "         'earths': 3,\n",
       "         'stripe': 1,\n",
       "         'zatko': 1,\n",
       "         'steam': 3,\n",
       "         'joe': 1,\n",
       "         'realworld': 3,\n",
       "         'instagram': 4,\n",
       "         'materials science': 1,\n",
       "         'australia': 2,\n",
       "         'tesla north america': 1,\n",
       "         'gt50': 1,\n",
       "         'north america': 3,\n",
       "         'block': 4,\n",
       "         'sun': 7,\n",
       "         'civilizations': 4,\n",
       "         'gwhdaykm2': 1,\n",
       "         'mount': 1,\n",
       "         'graffiti': 1,\n",
       "         'apple': 2,\n",
       "         'tesla service': 2,\n",
       "         'hopefully': 12,\n",
       "         'powerwall': 4,\n",
       "         'fusion': 2,\n",
       "         'david sacks': 1,\n",
       "         'rings': 2,\n",
       "         'hobbit': 1,\n",
       "         'peter jackson': 1,\n",
       "         'book': 7,\n",
       "         'jackson': 2,\n",
       "         'tesla powerwall': 1,\n",
       "         'galadriel': 1,\n",
       "         'tolkien': 1,\n",
       "         'south korea': 3,\n",
       "         'chris': 1,\n",
       "         'raptor': 8,\n",
       "         'h2': 1,\n",
       "         'ch4': 1,\n",
       "         'deltav': 2,\n",
       "         'moodys': 1,\n",
       "         'hope connor': 1,\n",
       "         '1k': 1,\n",
       "         'diet coke': 2,\n",
       "         'gnus': 1,\n",
       "         'dane': 1,\n",
       "         'gam': 1,\n",
       "         'universe': 8,\n",
       "         'mark': 3,\n",
       "         'mobile': 5,\n",
       "         'v2': 4,\n",
       "         'monday': 1,\n",
       "         'ron barron': 1,\n",
       "         'james': 3,\n",
       "         'mechazilla': 1,\n",
       "         'spam': 6,\n",
       "         'board': 11,\n",
       "         'october': 1,\n",
       "         'st halloween': 1,\n",
       "         'halloween': 2,\n",
       "         'standard model': 1,\n",
       "         'model': 15,\n",
       "         'san antonio': 1,\n",
       "         'vegas': 4,\n",
       "         'tesla softwareai': 1,\n",
       "         'september': 1,\n",
       "         'sept': 1,\n",
       "         'forward10': 1,\n",
       "         'tesla autopilotai': 2,\n",
       "         'tesla autopilot softwareai': 1,\n",
       "         'po box': 1,\n",
       "         'box': 2,\n",
       "         'stanford': 1,\n",
       "         'bill nix': 1,\n",
       "         'free willy': 1,\n",
       "         'magic moment': 1,\n",
       "         'mars bars': 1,\n",
       "         'mercury': 1,\n",
       "         'cocacola': 3,\n",
       "         'youtube': 4,\n",
       "         'manchester united ur': 1,\n",
       "         'ur': 3,\n",
       "         'democratic party': 2,\n",
       "         'republican party': 1,\n",
       "         'republican': 7,\n",
       "         'total teslas': 1,\n",
       "         'giga shanghai': 1,\n",
       "         'teslas': 7,\n",
       "         'waitlist': 1,\n",
       "         'sex': 3,\n",
       "         'b7': 1,\n",
       "         'scam odowd': 1,\n",
       "         'guardian': 1,\n",
       "         'tesla fremont': 3,\n",
       "         'fremont': 3,\n",
       "         'spacex falcon': 5,\n",
       "         '50year': 1,\n",
       "         'saxon james musk': 1,\n",
       "         'lt5': 5,\n",
       "         'sec': 2,\n",
       "         'starship booster': 1,\n",
       "         'send podcast': 1,\n",
       "         'senator manchin': 1,\n",
       "         'destiny': 1,\n",
       "         'austin international': 1,\n",
       "         'cnbc': 1,\n",
       "         'colbert report': 1,\n",
       "         'jon stewart daily show': 1,\n",
       "         'economist': 1,\n",
       "         'oldschool': 1,\n",
       "         'jon': 2,\n",
       "         'floki': 1,\n",
       "         'thanksgiving': 1,\n",
       "         'harley quinn': 1,\n",
       "         'races': 1,\n",
       "         'twitter gt twizzler': 1,\n",
       "         'shortville': 1,\n",
       "         'wikipedia': 3,\n",
       "         'hubris': 2,\n",
       "         'intergalactic': 1,\n",
       "         'sub': 2,\n",
       "         'god': 1,\n",
       "         'sergey': 3,\n",
       "         'wsj': 3,\n",
       "         'satan': 1,\n",
       "         'business insider trading': 3,\n",
       "         'insider trading': 3,\n",
       "         'attack chihuahuas': 1,\n",
       "         'sickonolfis': 1,\n",
       "         'supernova': 1,\n",
       "         'singlepiece': 1,\n",
       "         'das bootdas baby': 1,\n",
       "         'high seas': 1,\n",
       "         'fbi': 2,\n",
       "         'fud': 2,\n",
       "         'nicole': 1,\n",
       "         'nighti': 1,\n",
       "         'disney': 2,\n",
       "         'ferdinand piëch': 1,\n",
       "         'moon': 5,\n",
       "         'gestalt': 1,\n",
       "         'formula': 1,\n",
       "         'china': 9,\n",
       "         'expendable': 3,\n",
       "         'airbnb': 1,\n",
       "         'giga nevada': 2,\n",
       "         'bf': 1,\n",
       "         'andromeda': 1,\n",
       "         'ppmgt1000': 1,\n",
       "         'co2': 1,\n",
       "         'propellant': 1,\n",
       "         'tw': 1,\n",
       "         'throughput': 2,\n",
       "         'charlie ergen': 1,\n",
       "         'assumes': 1,\n",
       "         'magellanic clouds': 1,\n",
       "         'steel': 1,\n",
       "         'tvc': 2,\n",
       "         'shrouds': 3,\n",
       "         'mox': 1,\n",
       "         'hydraulics': 1,\n",
       "         'chucks': 1,\n",
       "         'msnbc': 1,\n",
       "         'imagine': 2,\n",
       "         'fifth element': 1,\n",
       "         'doom': 1,\n",
       "         'greece': 1,\n",
       "         'american caesar masters': 1,\n",
       "         'audible': 1,\n",
       "         'biden': 2,\n",
       "         'trump': 5,\n",
       "         'desantis': 2,\n",
       "         'united states': 2,\n",
       "         'trumps': 1,\n",
       "         'hat': 3,\n",
       "         'dems': 4,\n",
       "         'dark moon': 1,\n",
       "         'ruin': 1,\n",
       "         'mimic': 1,\n",
       "         'emf': 1,\n",
       "         'president': 4,\n",
       "         'douglas adams': 1,\n",
       "         'clams': 1,\n",
       "         'musk foundation': 1,\n",
       "         'tokyo': 1,\n",
       "         'terracotta army': 1,\n",
       "         'beijing': 1,\n",
       "         'xian': 1,\n",
       "         'japan': 3,\n",
       "         '150kmonth': 1,\n",
       "         'van': 2,\n",
       "         'robovan': 1,\n",
       "         'time machine': 1,\n",
       "         'delorean': 1,\n",
       "         'minute doc': 1,\n",
       "         'mike duncan': 1,\n",
       "         'orwell': 2,\n",
       "         'zip': 1,\n",
       "         'sock': 5,\n",
       "         'sock con': 1,\n",
       "         'aficionado': 1,\n",
       "         'chart': 1,\n",
       "         'elvis': 1,\n",
       "         'happy july': 1,\n",
       "         'july': 2,\n",
       "         'talulah': 1,\n",
       "         'venice': 2,\n",
       "         'sjm': 3,\n",
       "         'beverly hills cheese shop': 1,\n",
       "         'stilton': 1,\n",
       "         'dogecoin': 4,\n",
       "         'gwynne': 1,\n",
       "         'happy fathers day': 1,\n",
       "         'stinky': 1,\n",
       "         'areof pastpresentand future': 1,\n",
       "         'comme ci comme': 1,\n",
       "         'weird': 3,\n",
       "         'isp': 1,\n",
       "         'idiocracy': 1,\n",
       "         'hyundai': 1,\n",
       "         'awe': 1,\n",
       "         'fred astaire': 1,\n",
       "         'top gun': 2,\n",
       "         'yang': 1,\n",
       "         'super moderate super pac': 1,\n",
       "         'mayra flores': 1,\n",
       "         'starship sn24': 1,\n",
       "         'tesla fsd': 3,\n",
       "         'august': 1,\n",
       "         'mega bay': 1,\n",
       "         'boca chica': 1,\n",
       "         'dogs': 2,\n",
       "         'rhd': 2,\n",
       "         'merlin': 1,\n",
       "         'lister': 1,\n",
       "         'bay area': 3,\n",
       "         'karate kid': 1,\n",
       "         'starlink eg league': 1,\n",
       "         'multiplayer': 1,\n",
       "         'league': 3,\n",
       "         'mdma': 1,\n",
       "         'doctor strange': 1,\n",
       "         'multiverse': 1,\n",
       "         'recirc': 1,\n",
       "         'wolf': 1,\n",
       "         'elden ring': 8,\n",
       "         'imo': 12,\n",
       "         '8k': 1,\n",
       "         'juliet': 1,\n",
       "         'romeo': 1,\n",
       "         'shakespeares': 1,\n",
       "         'tempest': 1,\n",
       "         'noahs arks': 1,\n",
       "         'earth humanity': 1,\n",
       "         'eu': 1,\n",
       "         'oscars': 1,\n",
       "         'maxwell': 1,\n",
       "         'doj': 1,\n",
       "         'falcon heavy': 1,\n",
       "         'nv': 1,\n",
       "         'el camino jack': 1,\n",
       "         'jack': 5,\n",
       "         'coup': 1,\n",
       "         'grâce': 1,\n",
       "         'johnny rotten': 1,\n",
       "         'mr president': 1,\n",
       "         'house senate': 1,\n",
       "         'max': 2,\n",
       "         'bob': 2,\n",
       "         'americans executive': 1,\n",
       "         'democrat': 3,\n",
       "         'rick caruso': 1,\n",
       "         'los angeles': 1,\n",
       "         'vision nns': 1,\n",
       "         'bill harris': 1,\n",
       "         'intuit': 1,\n",
       "         'xpaypal': 1,\n",
       "         'march': 1,\n",
       "         'lgbtq': 1,\n",
       "         'billys': 1,\n",
       "         'palmer': 2,\n",
       "         'python': 3,\n",
       "         'javascript': 1,\n",
       "         'jackson palmer': 1,\n",
       "         'mackenzie ahem scott': 1,\n",
       "         'looney tunes': 2,\n",
       "         'demonizing': 1,\n",
       "         'romney': 1,\n",
       "         'pacs': 1,\n",
       "         'agi': 2,\n",
       "         'democrats': 1,\n",
       "         'hillary': 1,\n",
       "         'patch': 1,\n",
       "         'linux': 1,\n",
       "         'gates': 3,\n",
       "         'providing internet': 1,\n",
       "         'nigeria': 1,\n",
       "         'twitterso': 1,\n",
       "         'covid': 3,\n",
       "         'eg snapchat': 1,\n",
       "         'dogecoin trillionaire': 1,\n",
       "         'tesla shanghai': 1,\n",
       "         'cox': 1,\n",
       "         'cape canaveralhumans': 1,\n",
       "         'intdex': 2,\n",
       "         'dna': 2,\n",
       "         'aramco': 1,\n",
       "         'iron man': 1,\n",
       "         'iron': 4,\n",
       "         'def': 1,\n",
       "         'italy': 1,\n",
       "         'hong kong': 1,\n",
       "         'world bank': 1,\n",
       "         'starman roadster': 1,\n",
       "         'roadster': 2,\n",
       "         'space shuttle': 1,\n",
       "         'netflix': 2,\n",
       "         'california tesla': 2,\n",
       "         'ev': 2,\n",
       "         'mi6': 1,\n",
       "         'russiatrump': 1,\n",
       "         'clinton campaign': 5,\n",
       "         'clinton': 5,\n",
       "         'catherine': 1,\n",
       "         'lawyers': 2,\n",
       "         'perkins': 1,\n",
       "         'cooley': 1,\n",
       "         'chad': 1,\n",
       "         'fbi source': 1,\n",
       "         'sussmann': 2,\n",
       "         'hoax': 5,\n",
       "         'brazil': 1,\n",
       "         'edit': 2,\n",
       "         'diehard dem': 1,\n",
       "         'adminstration': 1,\n",
       "         'metoo': 1,\n",
       "         'elongate': 1,\n",
       "         'bi': 1,\n",
       "         'la': 1,\n",
       "         'republicans': 2,\n",
       "         'housesenatepresident': 1,\n",
       "         'reps': 1,\n",
       "         'yale': 2,\n",
       "         'exxon': 1,\n",
       "         'sandp': 1,\n",
       "         'shame': 2,\n",
       "         'twitters': 3,\n",
       "         'aspergers': 1,\n",
       "         'aisoftwarechip': 1,\n",
       "         'gt95': 1,\n",
       "         'yesterday twitters ceo': 1,\n",
       "         'twitters sec': 1,\n",
       "         'billy': 1,\n",
       "         'borderline': 1,\n",
       "         'golden state': 1,\n",
       "         'nda': 1,\n",
       "         'illuminaughty': 1,\n",
       "         'select latest': 1,\n",
       "         'lib': 1,\n",
       "         'libs': 1,\n",
       "         'dmca': 1,\n",
       "         'semirandom': 1,\n",
       "         'tesla china': 2,\n",
       "         'claws': 1,\n",
       "         'bioshock': 1,\n",
       "         'dead space': 1,\n",
       "         'taj mahal': 1,\n",
       "         'knowin': 1,\n",
       "         'nazi': 1,\n",
       "         'core code': 1,\n",
       "         'wedthurs': 1,\n",
       "         'vector': 2,\n",
       "         'truth social': 3,\n",
       "         'passiveindex': 2,\n",
       "         'passive': 2,\n",
       "         'george': 2,\n",
       "         'freemasons': 1,\n",
       "         '110k': 1,\n",
       "         'aggro255': 1,\n",
       "         'npc': 1,\n",
       "         'met': 1,\n",
       "         'vanity fair': 1,\n",
       "         'nbc': 1,\n",
       "         'ludendorff': 1,\n",
       "         'shadow crew': 1,\n",
       "         'shadrow crew': 1,\n",
       "         'bitcoin': 2,\n",
       "         'lotbuy': 1,\n",
       "         'munger': 2,\n",
       "         'jack bogle': 1,\n",
       "         'vanguard': 1,\n",
       "         'ritalin': 2,\n",
       "         'adderall': 2,\n",
       "         'wellbutrin': 1,\n",
       "         'obama': 1,\n",
       "         'trumpet': 2,\n",
       "         'kicks red bulls': 1,\n",
       "         'scifi': 1,\n",
       "         'vegas boring co': 1,\n",
       "         'boring co': 3,\n",
       "         'washington post': 1,\n",
       "         'apple store': 1,\n",
       "         'san francisco': 1,\n",
       "         'wall st': 1,\n",
       "         'tesla cfo': 1,\n",
       "         'ltlt1000 future gen neuralinks': 1,\n",
       "         'neuralinks': 3,\n",
       "         'ozempicrybelsus': 1,\n",
       "         'alzheimers': 1,\n",
       "         'cnc': 1,\n",
       "         'shadow ban council': 1,\n",
       "         'nyt': 1,\n",
       "         'ted': 2,\n",
       "         'crypto': 3,\n",
       "         'kafka': 1,\n",
       "         'barbarians': 1,\n",
       "         'gate': 1,\n",
       "         'spacex tesla neuralink': 1,\n",
       "         'spacex tesla': 2,\n",
       "         'vw': 1,\n",
       "         'mgmt': 1,\n",
       "         'tzero': 1,\n",
       "         'jb': 2,\n",
       "         'resistance': 2,\n",
       "         'tesla spacex': 1,\n",
       "         'walter isaacson': 1,\n",
       "         'eberhard': 4,\n",
       "         'shell corp': 2,\n",
       "         'paypal': 1,\n",
       "         'tesla motors': 1,\n",
       "         'ac propulsions tzero': 1,\n",
       "         'boring company': 2,\n",
       "         'pinball wizard': 1,\n",
       "         'connector': 2,\n",
       "         'superchargers': 1,\n",
       "         'kingdom': 1,\n",
       "         'kingdoms': 1,\n",
       "         'disconnected': 1,\n",
       "         'truman show': 1,\n",
       "         'master chief': 1,\n",
       "         'tesla texas teambuilt': 1,\n",
       "         'gigafactory texas grand': 1,\n",
       "         'fps': 1,\n",
       "         'hz': 1,\n",
       "         'earthsolar': 1,\n",
       "         'parag': 1,\n",
       "         'facebook': 1,\n",
       "         'ds3': 1,\n",
       "         'spain': 1,\n",
       "         '100mw': 1,\n",
       "         'george lucas': 1,\n",
       "         'star wars': 1,\n",
       "         'shakespeare': 1,\n",
       "         'devil incarnate': 1,\n",
       "         'einstein': 1,\n",
       "         'berghain': 1,\n",
       "         'oneweb': 1,\n",
       "         'lhd': 1,\n",
       "         'uaw': 4,\n",
       "         'original halo': 1,\n",
       "         'smash bros': 1,\n",
       "         'finished halo infinite': 1,\n",
       "         'halo infinite': 2,\n",
       "         'cyberpunk': 1,\n",
       "         'longrange fov': 1,\n",
       "         'covid19 anymorei': 1,\n",
       "         'covid19': 2,\n",
       "         'theseus': 2,\n",
       "         'washington posts': 1,\n",
       "         'democracy': 3,\n",
       "         'catchy': 1,\n",
       "         'barry white': 1,\n",
       "         'toronto': 1,\n",
       "         'gaslight': 1,\n",
       "         'first starship': 1,\n",
       "         'starship rough': 1,\n",
       "         'giga berlinbrandenburg': 2,\n",
       "         'disc': 2,\n",
       "         'chrysler': 1,\n",
       "         'agoford': 1,\n",
       "         'master plan part': 1,\n",
       "         'realworld ai': 3,\n",
       "         'chechen republic': 1,\n",
       "         'ramzan kadyrov': 1,\n",
       "         'достоевский идиот': 1,\n",
       "         'же несчастная дура': 1,\n",
       "         'дура': 1,\n",
       "         'умом без сердца': 1,\n",
       "         'на этот': 1,\n",
       "         'вы': 1,\n",
       "         'честью': 1,\n",
       "         'україна': 1,\n",
       "         'путин': 1,\n",
       "         'bitcoin ethereum': 1,\n",
       "         'united earth': 1,\n",
       "         'encanta el mariachi': 1,\n",
       "         'forbidden cereal': 1,\n",
       "         'heating': 1,\n",
       "         'antarctic': 1,\n",
       "         'fukushima': 1,\n",
       "         'radiation': 1,\n",
       "         'polaris': 1,\n",
       "         'tuesday': 1,\n",
       "         'friday': 1,\n",
       "         'space station': 1,\n",
       "         'pshaw': 1,\n",
       "         'nikola tesla': 1,\n",
       "         'faraday': 1,\n",
       "         'ac': 1,\n",
       "         'qa': 1,\n",
       "         'strong ukraine': 1,\n",
       "         'extraordinary': 1,\n",
       "         'mich recht herzlich': 1,\n",
       "         'ich': 1,\n",
       "         'zukunft': 1,\n",
       "         'viasat ukraine': 1,\n",
       "         'former': 4,\n",
       "         'leavei': 1,\n",
       "         'row iv': 1,\n",
       "         'saudi arabia': 1,\n",
       "         'lucid': 1,\n",
       "         'fart': 1,\n",
       "         'successful starlink': 1,\n",
       "         'tonga': 1,\n",
       "         'lidar': 1,\n",
       "         'iss': 1,\n",
       "         'hollywood': 2,\n",
       "         'dweeb': 1,\n",
       "         'imessage': 1,\n",
       "         'discord': 1,\n",
       "         'rust': 1,\n",
       "         'night city': 1,\n",
       "         'norway': 1,\n",
       "         'irs': 1,\n",
       "         'dc': 1,\n",
       "         'faa': 1,\n",
       "         'gulfstreams': 1,\n",
       "         'april': 1,\n",
       "         'ðoge': 1,\n",
       "         'new zealand': 1,\n",
       "         'dave lee': 1,\n",
       "         'dave': 2,\n",
       "         'tim': 1,\n",
       "         'tesla fsd ai': 1,\n",
       "         'jared': 1,\n",
       "         'super heavy booster': 1,\n",
       "         'earth todayit': 1,\n",
       "         'rogan fridman dodd ted': 1,\n",
       "         'vegas convention center': 1,\n",
       "         'resorts world': 1,\n",
       "         'gavin': 1,\n",
       "         'thursday': 1,\n",
       "         'necessary': 1,\n",
       "         'note starlink': 1,\n",
       "         'starbase texas': 1,\n",
       "         'scan': 1,\n",
       "         'harbinger': 1,\n",
       "         'denmark': 1,\n",
       "         'og covid19': 1,\n",
       "         'hydrogen sonata': 1,\n",
       "         'manganese': 2})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "keyphrases = []\n",
    "for entry in df['Noun_Keyphrases'].values:\n",
    "    keyphrases += entry\n",
    "Counter(keyphrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 13:36:20,321 loading file C:\\Users\\baira\\.flair\\models\\pos-english\\a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
      "2022-11-29 13:36:21,134 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    }
   ],
   "source": [
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/pos-english\")\n",
    "\n",
    "def flair_pos_tagging(sentence):\n",
    "    # print(sentence)\n",
    "    verbs = set()\n",
    "    adjectives = set()\n",
    "    sen = Sentence(sentence)\n",
    "    tagger.predict(sen)\n",
    "\n",
    "    for label in sen.get_labels('pos'):\n",
    "        \n",
    "        if label.value[0:2] == 'VB' and label.score > 0.75:\n",
    "            verbs.add(label.data_point.text)\n",
    "            # print(verbs)\n",
    "        if label.value[0:2] == 'JJ' and label.score > 0.75:\n",
    "            adjectives.add(label.data_point.text)\n",
    "            # print(adjectives)\n",
    "\n",
    "    return list(verbs), list(adjectives)\n",
    "\n",
    "df['verbs'], df['adjectives'] = zip(*df['Cleaned_Tweets'].str.lower().apply(flair_pos_tagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[dear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[meeting]</td>\n",
       "      <td>[cool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[let, sink, entering]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[get, are]</td>\n",
       "      <td>[underappreciated, local]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bats]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>[requires, operates]</td>\n",
       "      <td>[less, higher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>[scaling, is]</td>\n",
       "      <td>[several]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>[paid, are]</td>\n",
       "      <td>[high, responsible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>[be, voted]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>[are]</td>\n",
       "      <td>[free]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2094 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      verbs                 adjectives\n",
       "0                        []                     [dear]\n",
       "1                 [meeting]                     [cool]\n",
       "2     [let, sink, entering]                         []\n",
       "3                [get, are]  [underappreciated, local]\n",
       "4                    [bats]                         []\n",
       "...                     ...                        ...\n",
       "2089   [requires, operates]             [less, higher]\n",
       "2090          [scaling, is]                  [several]\n",
       "2091            [paid, are]        [high, responsible]\n",
       "2092            [be, voted]                         []\n",
       "2093                  [are]                     [free]\n",
       "\n",
       "[2094 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['verbs','adjectives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_to_remove = ['get','are','is','am','have','has','been','seen','had','do','took','be',\n",
    "                    'make','does','like','did','see','was','go','got','get','want','getting','gets', 'exist',\n",
    "                    'done','doing','went','uses','says','known','let','given' ,'gave','makes','goes',\n",
    "                    'gone','going','saw','being','were']\n",
    "\n",
    "def remove_words(row):\n",
    "    verbs_list = []\n",
    "\n",
    "    if len(row) > 0:\n",
    "        for i in row:\n",
    "            if i not in verbs_to_remove:\n",
    "                verbs_list.append(i)\n",
    "    return verbs_list                  \n",
    "\n",
    "df['verbs'] = df['verbs'].apply(remove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# keyphrases = df1['verbs'].explode().dropna().to_list()\n",
    "# word_could_dict = Counter(keyphrases)\n",
    "# wordcloud = WordCloud(width = 1000, height = 500, background_color = \"white\").generate_from_frequencies(word_could_dict)\n",
    "# # Word Cloud Visual\n",
    "# plt.figure(figsize=(10,14))\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_to_remove = ['many','most','much','such']\n",
    "\n",
    "def remove_words(row):\n",
    "    adj_list = []\n",
    "\n",
    "    if len(row) > 0:\n",
    "        for i in row:\n",
    "            if i not in adj_to_remove:\n",
    "                adj_list.append(i)\n",
    "    return adj_list                  \n",
    "\n",
    "df['adjectives'] = df['adjectives'].apply(remove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# keyphrases = df1['adjectives'].explode().dropna().to_list()\n",
    "# word_could_dict = Counter(keyphrases)\n",
    "# wordcloud = WordCloud(width = 1000, height = 500, background_color = \"white\").generate_from_frequencies(word_could_dict)\n",
    "# # Word Cloud Visual\n",
    "# plt.figure(figsize=(10,14))\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_to_remove = ['ft', 'tbc', 'gt50' , '50year' , 'bro' , 'lt5', 'україна', 'thursday', '110k', 'friday' , 'tbh', 'qa', 'haha' ,\n",
    "                 'ac', 'november', 'sept' , 'lhd', 'rhd', 'вы', 'bf' , 'fsd' , 'us', 'fud', 'gwhdaykm2', 'irs', 'lib', 'libs', 'mgmt',\n",
    "                 'умом без сердца', 'fps', 'venn', 'cnc', 'hz' , 'def', '8k' , 'nighti', 'encanta el mariachi', 'forward10', 'ich',\n",
    "                 'isp', 'comme ci comme', 'la', 'ludendorffs', 'july', 'ðoge', 'siegel', 'zaporizhzhia', 'h2', 'ron barron', 'sjm', 'doj',\n",
    "                 'talulah', 'starlink eg league', 'areof pastpresentand future', 'mr president', 'bs', 'el camino jack', 'jb', 'nyt',\n",
    "                 'честью', 'das bootdas baby', 'zukunft', 'gnus', 'yang', 'august', 'reps', 'btw', 'wsj', 'covid19 anymorei',\n",
    "                 'ozempicrybelsus', 'дура', 'charlie ergen', 'dec', 'october', '1k', '100mw', 'mdma', 'un ass', 'donbas', 'gwynne',\n",
    "                 'ppmgt1000', 'же несчастная дура', 'awe', 'mf', 'kbg', 'nn', 'ch4', 'kg', 'bf16', 'thingreal', 'uaw', 'pshaw',\n",
    "                 'на этот', 'faa', 'row iv', 'ev', 'gm', 'kph', 'haha', 'b7', 'may', 'zatko', 'eu', 'un', 'nv', 'tw', 'gt95', 'mps',\n",
    "                 'q2', 'ur', 'путин', 'agoford', 'leavei', 'vw', 'ferdinand piëch', 'giga berlinbrandenburg', 'satan', 'das baby',\n",
    "                 'cape canaveralhumans', 'chad', 'hijinks']\n",
    "\n",
    "def remove_words(row):\n",
    "    noun_list = []\n",
    "\n",
    "    if len(row) > 0:\n",
    "        for i in row:\n",
    "            if i not in noun_to_remove:\n",
    "                noun_list.append(i)\n",
    "    return noun_list                  \n",
    "\n",
    "df['Noun_Keyphrases'] = df['Noun_Keyphrases'].apply(remove_words)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('./data/processed_data.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "880a1bcb285125bf82029bc72cd0bc47a12eb676d7c73f18db4b82ad2150951f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
